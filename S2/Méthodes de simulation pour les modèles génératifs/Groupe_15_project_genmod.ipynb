{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"b869a594271f4e8f94132793651657a7","deepnote_cell_type":"markdown"},"source":"## $\\quad$ $\\quad$  $\\quad$  $\\quad$  $\\quad$  $\\quad$  Gasset Mathieu - Guerin Cyril - Pot Eline","block_group":"393589df241c485aa3f7e7f4584be270"},{"cell_type":"markdown","metadata":{"cell_id":"9394a53d9e4448cba8bc6c4b35266661","deepnote_cell_type":"markdown"},"source":"-----------------------------------------------------------------------------------------------------------------------------------------------------------------","block_group":"59df7f278137410dbbc9f6399e9ed9d9"},{"cell_type":"markdown","metadata":{"cell_id":"cae5a6d1047d4c118e7a69de57b85d39","deepnote_cell_type":"markdown"},"source":"## $\\quad$ Adaptive Tuning Of Hamiltonian Monte Carlo Within Sequential Monte Carlo","block_group":"29c9d6a33e9244beb7fcf2be83685df7"},{"cell_type":"markdown","metadata":{"cell_id":"bdaca0710b814b00b2f3199b14add9cd","deepnote_cell_type":"markdown"},"source":"### Sorbonne Université $\\quad$ $\\quad$ $\\quad$ $\\quad$ $\\quad$ $\\quad$  $\\quad$  $\\quad$  $\\quad$ $\\quad$  $\\quad$  $\\quad$  $\\quad$  $\\quad$  $\\quad$  $\\quad$ $\\quad$  Modèles génératifs","block_group":"ccd4db51326e4bfa8fda9978929825ff"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"88cf0ad0bb344561b9fcf843c7b6600b","deepnote_cell_type":"text-cell-h3"},"source":"### Introduction","block_group":"146dc53babc0496b923f96e8e349d6fa"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"56c0586b63a5484da9d3c50a518f131f","deepnote_cell_type":"text-cell-p"},"source":"Les SMC offrent une stratégie pour approcher une distribution cible en échantillonnant des particules depuis une distribution initiale et en les déplaçant à travers une séquence de distributions intermédiaires. Cette approche permet l'estimation de constantes de normalisation, ce qui est utile pour la sélection de modèles. Cependant l'efficacité des échantillonneurs SMC dépend grandement des noyaux de Markov utilisés. Ainsi cet article explore l'intégration des noyaux sélectionné par la méthode de Monte Carlo Hamiltonienne et donc de ces avantages par rapport à des méthodes plus classiques comme MCMC.","block_group":"2fb618bc5ebb4a259a65fd50e900f434"},{"cell_type":"markdown","metadata":{"cell_id":"792ff0ed18b94f0084f67358a271f769","deepnote_cell_type":"markdown"},"source":"### $\\textbf{Contexte}$","block_group":"3170c080a222451ca18504eaa021adc7"},{"cell_type":"markdown","metadata":{"cell_id":"b4bcb32475134fd2aae607ddea3133fd","deepnote_cell_type":"markdown"},"source":"Soit $(\\Omega, \\mathcal{F}, \\mathbb{P})$ un espace de probabilité. Soit $X$ : $(\\Omega,\\mathcal{F}) \\rightarrow \\mathbb{R}^d$ de loi a densite $p$ pour la mesure de Lebesgue et $Y$ : $(\\Omega,\\mathcal{F}) \\rightarrow E$ avec (E un espace Polonais) que l'on observe, de loi sachant $X$ a densite $\\pi(. | X)$ par rapport a une mesure $\\mu$ de $E$. On introduit $\\forall i \\in \\llbracket 1,N \\rrbracket, Y_i$ des copies i.i.d de $Y$. On définit la vraisemblance de $Y$ comme $l(Y_1, Y_2, \\ldots, Y_N|X) = \\prod_{i=1}^{N} \\pi{(Y_i|X)}$.\nLa formule de Bayes nous dit que la loi $\\Pi(.|Y)$ de $X \\, | \\, Y$ à une densité par rapport à la mesure de lebesgue, qui vaut\n\n$$\n\\pi(x|Y) = \\frac{\\pi(Y|x)p(x)}{\\int_{\\mathbb{R}^d} p(u)p(Y|u)d\\lambda_d(u)}\n$$\n\nAinsi nous avons les nommages suivantes : $\\newline$\n\n- $\\pi(.|Y)$ est la distribution a posteriori $X \\, | \\, Y$,\n- $\\pi(.|X)$ est la distribution de $Y \\, | \\, X$,\n- $p(.)$ est la distribution a priori de $X$,\n- Le dénominateur est la constante de renormalisation.\n\nSoit une fonction test $\\varphi : \\mathbb{R}^d \\rightarrow \\mathbb{R}$ tel que $\\varphi \\in L^1(\\mathbb{R})$ par rapport à $\\Pi(.|Y)$. On souhaite approximer la valeur :\n$$\n\\int_{\\mathbb{R}^d} \\varphi(x) \\pi(x|Y) d\\lambda_d(x).\n$$\n\nOn souhaite également estimer la vraisemblance marginale $Z = \\int_{\\mathbb{R}^d} \\pi(y|x) p(x) dx$","block_group":"daa90f9c315643a9a32175482653b914"},{"cell_type":"markdown","metadata":{"cell_id":"d6d2f07237104460bfa39a7a0cbc924b","deepnote_cell_type":"markdown"},"source":"### $\\textbf{I - Sequential Monte-Carlo avec la méthode MCMC}$","block_group":"58efcc2302424106abad9d9c13e65042"},{"cell_type":"markdown","metadata":{"cell_id":"79ce297d4531482ebade9462d7079e61","deepnote_cell_type":"markdown"},"source":"Les méthodes de Monte-Carlo séquentiel consistent en l'introduction d'une séquence de distributions intermédiaires, $\\forall$ t $\\in  \\llbracket 0,T \\rrbracket$, $ \\pi_0, \\ldots, \\pi_t, \\ldots, \\pi_T $, et telles que $\\pi_0$ soit la loi a priori $\\pi$ et soit $\\textbf{facile à échantillonner}$, nous avons aussi $ \\pi_T = \\pi(.|Y) $\n\nOn considère une suite $\\forall t \\in \\llbracket 0,T \\rrbracket$, $\\lambda_{t}$ avec $0 = \\lambda_0 < \\ldots < \\lambda_t < \\ldots < \\lambda_T = 1$ qui va nous permette d'introduire des distributions dites \"tempérées\". En effet, par proportionnalité, puisque le dénominateur est une constante, nous avons : $\\pi_t(.|X) \\propto p(.)\\pi(Y|.)$, en rajoutant l'exposant sur la vraisemblance nous obtenons les distributions tempérées : $\\pi_t(.|X) \\propto p(.)\\pi(Y|.)^{\\lambda_t}$.\n\nL'utilisation de ces types de distributions est utile pour la raison suivante : \n\n* $\\textbf{Transition douce vers la distribution a posteriori :}$ L'augmentation graduelle de $ \\lambda_t $ qui prends ces valeurs entre 0 et 1, conduit à une série de distributions intermédiaires qui se déplacent progressivement de la distribution a priori vers la distribution a posteriori. Quand $\\lambda_t$ augmente quand t augmente, la vraisemblance commence à influencer de plus en plus la forme de la distribution intermédiaire. La transition est progressive et permets donc d'éviter de rester coincé dans des extremas locaux.","block_group":"140cab7d501e45cabedeea6445d3db09"},{"cell_type":"markdown","metadata":{"cell_id":"71ee4060d7a14171941f2244d1120d82","deepnote_cell_type":"markdown"},"source":"<!-- $\\textbf{3 - Sequential Monte Carlo}$ : -->\n\nPour construire un échantillonneur à partir de cette méthode, on utilise la méthode SMC (Sequential Monte Carlo). \n<!-- Cette méthode consite à estimer progressivement notre distribution cible $\\pi_T$ en utilisant une suite de distributions intermédiaires $\\pi_t$ avec $t \\in \\llbracket 1, T \\rrbracket$ et d'ensemble de particules. -->\n\nDans la suite, on introduit à chaque temps $t \\in \\llbracket 1, T \\rrbracket$ une distribution tempérée et non normalisée associée à $\\pi(x)$, qui s'écrit : $\\gamma_t(x) = p(x) l(y|x)^{\\lambda_t}$. \n\nSon facteur de normalisation vaut $Z_t = \\int_{\\mathbb{R}^d} \\gamma_t(x) dx$.\n\n\n### Présentation de l'algorithme SMC\nL'algorithme SMC se déroule de la façon suivante:\n\n**Initialisation :** On commence, au temps $t=1$, avec un ensemble de $N$ particules initiales $(x_1^{i})_{i=1}^N \\sim \\pi$ qui représentent la distribution a priori de l'état du système qui sont i.i.d. On dispose également de la première température $\\lambda_0 = 0$. On a donc $\\gamma_{0}(.) = p(.)$\n\n**A chaque itération** $t \\in \\llbracket 2, T \\rrbracket $ **:**\n\nOn dispose de particules $(x_t^{i})_{i=1}^N$ et qu'on suppose distribuées suivant $\\pi_{t-1}$\n\nOn choisit la prochaine température $\\lambda_t \\in (\\lambda_{t-1}, 1]$.\nOn pose $\\gamma_{t}(.) = p(.)\\pi(Y|.)^{\\lambda_t}$. \n\nOn calcule les poids des particules définis par : $w_t^{i}=\\frac{\\gamma_t(x_t^{i})}{\\gamma_{t-1}(x_t^{i})}$ pour chaque particule $i$.\nCes poids nous indiquent si chaque nouvelle particule est pertinente et représentative dans l'approximation de la prochaine distribution $\\pi_t$, partant de la particule précédente. Notons que leur moyenne permet d'estimer le rapport $\\frac{Z_t}{Z_{t-1}}$ par Monte Carlo.\n\nOn ré-échantillonne les particules en fonction de leur poids pour obtenir un nouvel ensemble $\\{\\tilde{x}_{t}^{i}\\}$. Cela permet d'enlever les particules les moins informatives, et de conserver les particules les plus probablement correctes. Cela permettra d'avoir une meilleure approximation de $\\pi_t$.\n\n<!-- Supposons qu'au temps $t - 1$ on ait une approximation de particules de poids égaux $\\{\\tilde{x}_{t-1}^{i}\\}_{i=1:N}$ de $\\pi_{t-1}$ est disponible, avec des duplicatas possibles parmi les particules.  -->","block_group":"6f947b4b58184046a3a60066a7c84bbf"},{"cell_type":"markdown","metadata":{"cell_id":"911c8712b06f4cb8bfc74ecad6d4ca2e","deepnote_cell_type":"markdown"},"source":"\nCe nuage de particules est ensuite déplacé avec un noyau de Markov $K_{t+1}^h$, qui laisse la distribution $\\pi_t$ invariante : pour chaque $i$,\n$$\nx_{t+1}^{i} \\sim K_{t+1}^h(\\tilde{x}_{t}^{i}, dx).\n$$\n\nNotons que par construction du noyau par une méthode MCMC, notre noyau vérifie les conditions de la proposition suivante :\n**Proposition :** On considère un espace d'états E quelquonque. Soit $(X_{n})_{n \\geq 0}$, une chaine de markov de noyau markovien P, irréductible, qui vérifie la condition de Doeblin, alors pour toute loi initiale $v$ de $X_0$, la loi de $X_n$ converge en variation vers une probabilité $\\pi$. On a aussi que $\\pi$ est l'unique mesure de probabilité invariante pour $(X_{n})_{n \\geq 0}$\n\nAinsi, les particules parcourent l'espace d'état tout en se rapprochant de la loi cible $\\pi_{t}$\nPar conséquent, un ensemble de nouvelles particules $\\{x_{t+1}^{i}\\}_{i=1:N}$ est obtenue, de distribution proche de $\\pi_t$. \n\n**Sortie :** A la fin, on retourne l'ensemble des échantillons et de leur poids calculés à toutes les itérations : $\\{x_t^{i}, w_t^{i}\\}$.\nOn retourne aussi chaque estimateur des ratio des constantes de normalisations $\\widehat{\\frac{Z_t}{Z_{t-1}}} = \\frac{1}{N} \\sum_{i=1}^N w_t^{i}$ qui est un estimateur de Monte Carlo du ratio entier en échantillonnant sous $\\pi_{t-1}$.\nOn note qu'on a donc accès à un estimateur du ratio $\\frac{Z_T}{Z_0}$","block_group":"ec4663490e154f6da7ffc7f085f3d520"},{"cell_type":"markdown","metadata":{"cell_id":"2ec28d0519a746baaa8a7e9e91aae60d","deepnote_cell_type":"markdown"},"source":"Ainsi en faisant $\\textbf{T+1}$ itérations, on obtient des échantillons qui suivent la loi a posteriori $\\pi_T = \\pi(.|Y)$.\nIl ne nous reste donc plus qu'à faire une moyenne pour obtenir l'esperance de $\\varphi$ sous $\\pi_T$ par la loi forte des grands nombres.","block_group":"18fffcff8bb246f59b558f9f45d5de34"},{"cell_type":"markdown","metadata":{"cell_id":"f8346af33ec44c80a7faad7b232dd332","deepnote_cell_type":"markdown"},"source":"## $\\textit{Remarque}$:\n\nL'algorithme, d'après l'article, présente et propose une autre façon d'obtenir la loi a posteriori via un importance sampling. En effet, une fois l'algorithme terminé en $\\textbf{T}$ itérations, on possède des échantillons de la loi à $\\textbf{T-1}$. On a donc accès à des échantillons avec des poids ${\\{x_t^{i}, w_t^{i}\\}}_{i=1,...N ; t=1,...,T}$ qui vont servir à estimer la valeur de $\\varphi$ en espérance selon les lois cibles $\\pi_t$. \n\nPour ce faire, on utilise les notions d'Importance Sampling :\n\nIl faut d'abord s'assurer d'avoir l'hypothèse de domination entre $\\pi_{t+1}$ et $\\pi_{t}$. C'est à dire : $\\forall x \\in \\mathbb{R},  \\pi_{t-1}(x) = 0$ alors $\\pi_{t}(x) = 0$. Ici, c'est bien le cas puisque $\\pi_t$ est construit à partir de $\\pi_{t-1}$. \n<!-- puisque le temps t n'existe que si le temps t-1 a existé. -->\nAinsi en considérant la sortie de l'algorithme et par définition de $\\omega_{t}^{i}$, on a, par la loi forte des grands nombres: \n$$\n\\sum_{i=1}^N \\frac{\\varphi(x_{t}^{i})\\omega_{t}^{i}}{\\sum_{l=1}^N \\omega_{t}^{l}} \\overset{p.s.}{\\longrightarrow} \\mathbb{E}_{\\pi_{t}}[\\varphi(x)].\n$$\n\n\nUn poids élevé signifie que l'échantillon $x_{t}^{i}$ est plus représentatif de la distribution cible.","block_group":"d2176110bbcb4f8697cfa44b8d521389"},{"cell_type":"markdown","metadata":{"cell_id":"0c95db6212b444a985a22cbfc03b9188","deepnote_cell_type":"markdown"},"source":"Cette façon de procéder fonctionnerait tout aussi bien que la méthode qui consiste à faire $\\textbf{T+1}$ itérations. Dans la suite, nous avons choisi d'implémenter l'algorithme avec $\\textbf{T+1}$ itérations.","block_group":"7bb9872e03c64d8a803f8e03dd0f2ebb"},{"cell_type":"markdown","metadata":{"cell_id":"db4eb4ebe4aa436cb7fe83bd9e834900","deepnote_cell_type":"markdown"},"source":"$\\textbf{Tuning des lambda}$\n","block_group":"a1c51209ba58427493fbc2335c8871fc"},{"cell_type":"markdown","metadata":{"cell_id":"7ac421971a5e4544b5d6cbaaa774489e","deepnote_cell_type":"markdown"},"source":"Les $\\lambda$ sont adaptatifs, ainsi une méthode commune basé sur $\\textit{Jasra et al., 2011; Schafer and Chopin,\n2013}$ et $\\textit{effective sample size - Kong et al., 1994}$, $\\textit{Agapiou et al., 2017}$, est de regarder la mesure de performance pour les estimateurs d'importance sampling, noté $\\textit{ESS}$ :\n$$\nESS(\\lambda_t) = \\frac{\\left(\\sum_{i=1}^N w_t^i\\right)^2}{\\sum_{i=1}^N (w_t^i)^2},\n$$\noù $ w_t^i = \\frac{\\gamma_t(x_t^i)}{\\gamma_{t-1}(x_t^i)}$ $\\newline$ L'ESS est une approximation de Monte Carlo de $ N/(1 + \\chi^2(\\pi_t, \\pi_{t-1})) $ où $\\chi^2(\\pi_t, \\pi_{t-1})$ est la divergence $\\chi^2$ de $\\pi_{t-1}$ à $\\pi_t$.\nAinsi $\\lambda_t$ est choisit en résolvant (en $\\lambda$) l'équation $ ESS(\\lambda) = \\alpha N $, pour une valeur $\\alpha \\in (0,1)$ choisie.\n","block_group":"c3cf1f4d27d441aa9de411c83b7e1de9"},{"cell_type":"markdown","metadata":{"cell_id":"6cd72e87d12d47dd8a88005c17e4baf9","deepnote_cell_type":"markdown"},"source":"## $\\textbf{Expérimentation - SMC}$\n","block_group":"f397f74540fb433fb8a916aa1505ac31"},{"cell_type":"markdown","metadata":{"cell_id":"0e010e2c0a284de7b156804ad95c3303","deepnote_cell_type":"markdown"},"source":"Nous avons réimplémenté les algorithmes décrits par l'article (avec parfois quelques simplifications) et on les a testés sur des données générées avec $X\\sim\\mathcal{U}([0,1])$ et $Y\\sim \\mathcal{B}(X)^{\\otimes n}$.","block_group":"43b770f657ad4d919f7e14ed7e8b1e51"},{"cell_type":"code","metadata":{"source_hash":"39af22bb","execution_start":1713204157719,"execution_millis":603,"deepnote_to_be_reexecuted":false,"cell_id":"ee9b8db253b44c9c822c56f4104c2880","deepnote_cell_type":"code"},"source":"import torch\nimport numpy as np\nrng = np.random.default_rng()\ndevice = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\ndef SMC(Y, sample_X, N, p, l, K_markov, h, should_continue_markov, lambda_get):\n    X = sample_X(N)\n    t, lambda_tm1, lambda_t = 1, 0, lambda_get(1)\n\n    omegas = []\n    while lambda_t <= 1:\n        omega = l(Y, X)**(lambda_t - lambda_tm1)\n        omegas.append(omega)\n        omega = omega.squeeze().cpu().numpy()\n        Xtilde = torch.from_numpy(\n            rng.choice(X.cpu(), size=N, p=omega/omega.sum())\n        ).to(device)\n\n        X, Xk = Xtilde, X.clone()\n        while should_continue_markov(Xk):\n            X = K_markov(X, lambda x : p(x) * l(Y, x), h)\n            Xk = torch.cat((Xk, X), 1)\n\n        lambda_tm1 = lambda_t\n        lambda_t = lambda_get(t)\n        h.next_t()\n        t = t + 1\n    return X, omegas","block_group":"45b7925dc9104c3f8314e0cb638898a5","execution_count":1,"outputs":[{"name":"stdout","text":"cpu\n/shared-libs/python3.9/py/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/c4ff4b2d-f1a0-4a9f-9c81-3def0c58e497","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"1e24ca51","execution_start":1713204158330,"execution_millis":621,"deepnote_to_be_reexecuted":false,"cell_id":"0b50cf43ee4441e8920567a8f52efc8b","deepnote_cell_type":"code"},"source":"import scipy.stats\n\ndef sample_X(N):\n    return torch.rand((N, 1), device=device)\n\ndef p(X):\n    return (X >= 0) * (X <= 1)\n\ndef sample_Y(n):\n    X = torch.rand(1, device=device)\n    Y = (torch.rand(n, device=device) <= X).float()\n    return X, Y\n\ndef l(Y, X):\n    X = X.repeat(1, Y.shape[0])\n    return (X**Y * (1 - X)**(1 - Y)).prod(axis=-1, keepdim=True)\n\ndef K_markov(X, pi, h):\n    # Genere une les etats suivants des X pour un noyeau markovien de pi\n    N = X.shape\n    XS = (torch.rand(N, device=device) * (h.sup_bound - h.inf_bound)\n             + h.inf_bound + X)\n    U = torch.rand(N, device=device)\n    return torch.where(U <= pi(XS)/pi(X), XS, X)\n\ndef should_continue_markov(Xk):\n    return Xk.shape[1] <= 20\n\ndef lambda_get(N, t):\n    return t/N\n\nclass ClassicMcmcParameters:\n    def __init__(self, inf_bound, sup_bound):\n        self.inf_bound = inf_bound\n        self.sup_bound = sup_bound\n\n    def next_t(self):\n        pass\n\n\nN, n = 1000, 5\nXR, Y = sample_Y(n)\nprint(f\"Vrai X : {XR}, Y : {Y}\")\nprint(f\"Esperance a posteriori réelle : {scipy.stats.beta(1 + Y.sum().cpu(), 1 + n - Y.sum().cpu()).mean()}\")\n\nX, omegas = SMC(\n    Y, sample_X, N, p, l,\n    K_markov, ClassicMcmcParameters(-0.1, 0.1),\n    should_continue_markov, lambda t : lambda_get(10, t)\n)\nprint(f\"Estimateur de l'ésperance a posteriori selon SMC : {X.mean()}\")","block_group":"49ef664ac26c4e4f95ad17b125324f8b","execution_count":2,"outputs":[{"name":"stdout","text":"Vrai X : tensor([0.3528]), Y : tensor([0., 0., 0., 0., 1.])\nEsperance a posteriori réelle : 0.2857142984867096\nEstimateur de l'ésperance a posteriori selon SMC : 0.27261778712272644\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/5bab21ae-5725-4e7f-b449-0a2200627b7b","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"9aedfbb90cae4b6dbe895b00b4a93936","deepnote_cell_type":"markdown"},"source":"","block_group":"799b47a4576f411b920941131db067c6"},{"cell_type":"markdown","metadata":{"cell_id":"f901263149b446a79b2e4d43a79a972f","deepnote_cell_type":"markdown"},"source":"### $\\textbf{II - Hamiltonien MonteCarlo}$","block_group":"db86023ddd9e4ce297c8123b9e33da72"},{"cell_type":"markdown","metadata":{"cell_id":"4bd4398ed8f54740b0e0906c36bd44a8","deepnote_cell_type":"markdown"},"source":"La méthode de Hamiltonian MonteCarlo (HMC) est une méthode d'échantillonnage utilisée pour simuler des échantillons à partir de distributions de probabilité complexes et incalculable, en particulier dans des espaces de haute dimension. $\\newline$\nLa méthode consiste à construire un noyau markovien de Metropolis Hastings avec pour probabilité invariante :\n$$\n\\Pi = \\pi \\otimes \\mathcal{N}(0, M)\n$$\navec M une matrice symétrique définie positive.\n\nLa méthode HMC construit alors le noyau markovien $P$, qui est défini comme : \n$$\nP \\bigl( (p_t, q_t), (dp_{t+1}, dq_{t+1}) \\bigr) = \\frac{1}{(2 \\pi)^{\\frac{d}{2}}|M|^{\\frac{1}{2}}} e^{-\\frac{1}{2} q^{\\top}_{t+1} M q_{t+1}} \\delta_{\\phi(p_t, q_{t+1})}(p_{t+1})\n$$\n\n\nAvec $\\phi = s \\circ \\varphi_{\\kappa} : \\mathbb{R^d} \\times \\mathbb{R^d} \\rightarrow \\mathbb{R^d} \\times \\mathbb{R}^d$. Et où $\\varphi_{\\kappa}$ est le résultat au bout d'un temps $\\kappa$ d'une particule de position initiale $p_t$, d'énergie cinétique $q_t$, avec une énergie potentielle suivant la fonction $-log(\\pi)$  et  $\\begin{array}{l c c c} s : & \\mathbb{R^d} \\times \\mathbb{R^d} & \\longrightarrow & \\mathbb{R^d}  \\times \\mathbb{R^d} \\\\ & (p,q) & \\longrightarrow & (p,-q) \\end{array}$ \n\nCette définition de $P$ revient à dire que pour un état $(p_{t},q_{t})$, le couple de variables aléatoires $(p_{t+1},q_{t+1})$ résultant du noyau markovien pour cet état vérifie :\n$$\nq_{t+1} \\sim \\mathcal{N}(0, M),\\qquad p_{t+1} = \\phi(p_{t},q_{t+1})\n$$\n","block_group":"4529238e6ae041189b8d9a658d8d733a"},{"cell_type":"markdown","metadata":{"cell_id":"46273645b0e64f3eaff32b19783eb472","deepnote_cell_type":"markdown"},"source":"Dans cette situation, on obtient que la fonction $\\phi$ est une involution qui préserve le volume et conserve la quantité hamiltonienne $H$ définie par :\n$$\nH(p,q) = -log(\\pi) + \\frac{1}{2}q^{T}M^{-1}q\n$$ \n\nDans ce cas idéal, on a donc un noyau markovien $P$ de Métropolis Hastings avec pour probabilité invariante $\\Pi$ .\n\nMalheureusement en pratique, il est impossible de calculer $\\varphi_{\\kappa}$. On utilise donc une approximation, appelée Leapfrog integrator, qui est la suivante :\nPrenons $L \\in \\mathbb{N^*}$, $\\epsilon > 0$ tel que $\\kappa$ = $L \\epsilon$, et posons $\\varphi_{\\epsilon,L}(p_t, q_t) = (p_{t+\\kappa}, q_{t+\\kappa})$. Les $(p_{t+\\kappa}, q_{t+\\kappa})$ sont calculés de manière récursive, en prenant $\\tau = t + k \\epsilon$ avec $k = 0, ..., L-1$,  :\n$$\nq_{\\tau+\\epsilon/2} = q_{\\tau} + \\frac{\\epsilon}{2} \\nabla_p (log(\\pi(p_\\tau))), \\newline\n\n\np_{\\tau+\\epsilon} = p_{\\tau} + \\epsilon M^{-1} q_{t+\\epsilon/2}, \\newline\n\n\nq_{\\tau+\\epsilon} = q_{\\tau+\\epsilon/2} + \\frac{\\epsilon}{2} \\nabla_p (log(\\pi(p_{\\tau+\\epsilon}))),\n\n\n$$\nLa méthode préserve bien le volume et est une involution mais elle ne préserve pas la quantité hamiltonienne. Ainsi le noyau découlant de Métropolis Hastings dans ce cas a pour probabilité d'acceptation : \n$$ \n\\min \\left(1, \\frac{\\Pi(p_{t+\\kappa}, q_{t+\\kappa})}{\\Pi(p_{t}, q_{t})}\\right) = \\min \\left(1, \\frac{e^{-H(p_{t+\\kappa}, q_{t+\\kappa})}}{e^{-H(p_{t}, q_{t})}}\\right) = \\min \\biggl( 1, e^{-H(p_{t+\\kappa},q_{t+\\kappa}) + H(p_{t},q_{t})} \\biggr) = \\min \\biggl( 1, e^{\\Delta E_\\kappa} \\biggr)\n$$ \n ","block_group":"900cc3f0b0c8420783551e78777d8b2e"},{"cell_type":"markdown","metadata":{"cell_id":"d6e5260c594b40c99237f2c91ed6136a","deepnote_cell_type":"markdown"},"source":"## $\\textit{Remarque:}$\nL'article stipule que $\\Delta E_k = H(\\hat{q}_{\\tau+k}, \\hat{p}_{\\tau+k}) - H(q_\\tau, p_\\tau)$ or si on prend le cas $k$ = 1, et si $\\pi$ vaut 0 au temps suivant, alors on a $H$ = +$\\infty$, c'est-à-dire qu'on accepte tout le temps là où on devrait refuser. Ainsi, il semble plus raisonnable de prendre l'opposé : $\\Delta E_k =: H(q_\\tau, p_\\tau) - H(\\hat{q}_{\\tau+k}, \\hat{p}_{\\tau+k})$. ","block_group":"cc33abfb66854e1f97a993319f2bb1a3"},{"cell_type":"markdown","metadata":{"cell_id":"ff34dbc76fd140009d1e09bc9a4617cb","deepnote_cell_type":"markdown"},"source":"Ici, pour reprendre les notations de l'article, nos particules ont une position notée $x_t^i$, et on une vitesse qu'on notera $p_t^i$  pour $i=1,...,N$ et $t \\in \\llbracket 1,T\\rrbracket$","block_group":"e114214630274f5dba7b50cd8dd880e3"},{"cell_type":"markdown","metadata":{"cell_id":"f73a212d7d9f4bb2b52062a608b06ab5","deepnote_cell_type":"markdown"},"source":"## $\\textbf{Expérimentation HMC}$","block_group":"03f346ab2a3a44368a4d365189364db8"},{"cell_type":"code","metadata":{"source_hash":"d0dfb988","execution_start":1713204158953,"execution_millis":187,"deepnote_to_be_reexecuted":false,"cell_id":"40e62f063e8a42d58a484e88dfabdf1f","deepnote_cell_type":"code"},"source":"def K_HMC(X, pi, h):\n    p0, q0 = X.clone().requires_grad_(), torch.randn(X.shape, device=device)\n    p, q = p0, q0\n\n    for k in range(h.L):\n        grad_p = torch.where(pi(p) > 0, torch.autograd.grad(\n            torch.log(pi(p)), p, grad_outputs=torch.ones_like(p), create_graph=True\n        )[0], torch.zeros(p.shape, device=device))\n\n        q = q + h.epsilons/2 * grad_p\n        p = p + h.epsilons * q\n\n        grad_p = torch.where(pi(p) > 0, torch.autograd.grad(\n            torch.log(pi(p)), p, grad_outputs=torch.ones_like(p), create_graph=True\n        )[0], torch.zeros(p.shape, device=device))\n\n        q = q + h.epsilons/2 * grad_p\n\n    p0, q0 = p0.detach(), q0.detach()\n    p, q = p.detach(), q.detach()\n    \n    DeltaE = ((-torch.log(pi(p0)) + 1/2 * torch.einsum('ij,jk,ik->i', q0, h.M, q0).unsqueeze(1))\n              - (-torch.log(pi(p)) + 1/2 * torch.einsum('ij,jk,ik->i', q, h.M, q).unsqueeze(1)))\n    h.update_parameters(p0, q0, p, q, DeltaE)\n\n    U = torch.rand(p.shape, device=device)\n    return torch.where(torch.log(U) <= DeltaE, p, p0)","block_group":"90ca55a1054c4071951ae3dc8e684bd7","execution_count":3,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"56f6496f","execution_start":1713204158954,"execution_millis":8077,"deepnote_to_be_reexecuted":false,"cell_id":"d232a488ec12437f8deafb291d7e5e82","deepnote_cell_type":"code"},"source":"N, n = 500, 5\nXR, Y = sample_Y(n)\nprint(f\"Vrai X : {XR}, Y : {Y}\")\nprint(f\"Esperance a posteriori réelle : {scipy.stats.beta(1 + Y.sum().cpu(), 1 + n - Y.sum().cpu()).mean()}\")\n\nclass ClassicHmcParameters:\n    def __init__(self, epsilon, L, M, N):\n        self.epsilons = torch.ones((N, 1), device=device) * epsilon\n        self.M = M\n        self.L = L\n\n    def update_parameters(self, p0, q0, p, q, DeltaE):\n        pass\n\n    def next_t(self):\n        pass\n\nX = sample_X(N)\nh = ClassicHmcParameters(0.01, 10, torch.tensor([[1.]], device=device), N)\nfor i in range(N):\n    X = K_HMC(X, lambda x : p(x) * l(Y, x), h)\nprint(f\"Estimateur de l'esperance a posteriori selon HMC : {X.mean()}\")","block_group":"905c940e56354249bd8330f9a2ddcfea","execution_count":4,"outputs":[{"name":"stdout","text":"Vrai X : tensor([0.9618]), Y : tensor([1., 1., 1., 1., 1.])\nEsperance a posteriori réelle : 0.8571428656578064\nEstimateur de l'esperance a posteriori selon HMC : 0.8547757863998413\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/50d90f5b-ad94-4f47-af21-bf4c07a0b050","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"6dc9744f8bc04da694f431800b80dc40","deepnote_cell_type":"markdown"},"source":"### $\\textbf{III - Calibration par HMC de SMC}$","block_group":"927ca408fdd24d16ab615d8ad73fc226"},{"cell_type":"markdown","metadata":{"cell_id":"a26248e396844231b32d0591579aac1a","deepnote_cell_type":"markdown"},"source":"**Calibration de M:**\nDans cette partie, on calibre la matrice de covariance M utilisé dans la méthode HMC à chaque itération $t$ :\n$$\nM_t = \\text{diag}(\\widehat{\\text{Var}}_{\\pi_t}[p_t])^{-1}\n$$\nAvec $\\widehat{\\text{Var}}_{\\pi_t}[p_t]$ l'estimation de la matrice de covariance sous la loi $\\pi_{t}$.\n\nLe fait de calibrer cette matrice à partir de particules dont on dispose au temps $t$ permet d'exploiter l'information générée par ces particules. Par ailleurs, le fait de prendre une matrice diagonale permet une application plus aisée en grande dimension.","block_group":"414a4ec3c45b4a3aadccd3d2aba6a928"},{"cell_type":"markdown","metadata":{"cell_id":"73d606014c5349bc8d1ef8a7171607ad","deepnote_cell_type":"markdown"},"source":"**Calibration du noyau:**\n\nL'approche proposée par Fearnhead et Taylor (2013) pour la calibration des paramètres $h_t = (\\epsilon_t, L_t)$ du noyau $\\mathcal{K}_t^h$ pour la méthode SMC repose sur l'hypothèse que les paramètres $h$ du noyau utilisé au temps $t-1$ permettront d'avoir de bonnes performances au temps $t$.\n\nDans la suite, on se place donc au temps $t-1$ de l'algorithme SMC.\n\nIci, l'article reprend cette approche en la modifiant et en l'adaptant.","block_group":"67b002c3b0874bc6966dd55c87b9c556"},{"cell_type":"markdown","metadata":{"cell_id":"ae66685ae4e44597b6822b366b9e54d5","deepnote_cell_type":"markdown"},"source":"<!-- **1ere Etape :** -->\n\n* D'abord, on applique un premier HMC (pre-run) à chaque particule $x_i$, avec, pour chacune, un $(\\epsilon_i, L_i)$ différent, tirés aléatoirement.\n* On construit une nouvelle distribution $(\\epsilon, L)$ basé sur les performances des $(\\epsilon_i, L_i)_{i=1,...N}$. On utilise l'estimateur de Rao-Blackwellized comme métrique de performance.\n* On supprime les résultats du HMC obtenus.\n\n<!-- **2eme Etape :**  -->\n* On applique HMC aux $N$ particules, avec les paramètres $(\\epsilon, L)$, ce qui nous fait passer de $t-1$ à $t$.","block_group":"2b49e977f2fe42aa9718da3c0a01c2a8"},{"cell_type":"markdown","metadata":{"cell_id":"6cd00e09037341ce9daa18883b9b908c","deepnote_cell_type":"markdown"},"source":"Dans le meme esprit que Fearnhead et Taylor (2013), nous allons utiliser un estimateur qui nous permettra de paramétriser la sortie de l'algorithme. C'est à dire, d'assigner des poids $\\omega_{t}^{i}$ au couple $(\\epsilon_{t}^{i},L_{t}^{i})$.","block_group":"8a747a4409fc4971a814ed96ffcb3f0b"},{"cell_type":"markdown","metadata":{"cell_id":"bb61aab54ec64ee3b45cf45c435aae75","deepnote_cell_type":"markdown"},"source":"L'estimateur de Rao-Blackwellized s'écrit :\n\n$$\n\\tilde{\\Lambda} (\\tilde{x}_{t-1}^i, \\hat{x}_t^i) = \\frac{\\lVert \\tilde{x}_{t-1}^i - \\hat{x}_t^i \\rVert _M^2}{L} \\times \\min(1, \\exp (\\Delta E_t^i))\n$$\n\noù $\\hat{x}_t^i$ désigne la particule proposée par le flot Hamiltonien $\\varphi_{\\epsilon, L} (\\tilde{x}_{t-1}^i, p_t^i)$ avant l'étape de Metropolis Hasting et ${\\lVert . \\rVert _M}$ désigne la distance de Mahalanobis.\n\nOn note que le $\\min(1, \\exp (\\Delta E_t^i))$ sera utilisé pour les poids et est le taux d'acceptation du MH selon $\\Delta E_t^i$.","block_group":"bd6508bc73bd412793962fc5b774acbc"},{"cell_type":"markdown","metadata":{"cell_id":"452968857e3a4cf493dfaef0033bdfce","deepnote_cell_type":"markdown"},"source":"* Dans la première étape, on doit générer des $\\epsilon$ et des $L$ uniformément. En particulier, on prend : $\\epsilon \\sim \\mathcal{U}([0, \\epsilon^\\star])$ et $L\\sim \\mathcal{U}([0, L_{max}])$ pour des certains $\\epsilon^\\star$ et $L_{max}$ fixés.\n\n* Le processus pour calculer $\\epsilon^\\star$ est le suivant : \nL'idée est que si on observe différents $\\Delta E_t^i$ pour différentes valeurs de $\\hat{\\epsilon}_t^i$ et différents $(p_t^i, \\tilde{x}_{t-1}^i)$, alors on peut les utiliser pour ajuster un modèle de regression de la forme $|\\Delta E_t^i| = f(\\hat{\\epsilon}_t^i) + \\xi_t^i$ où $f : \\mathbb{R}^+ \\mapsto \\mathbb{R}^+$ et $\\xi_t^i$ est une variable aléatoire centrée, de variance finie.\n\nIci, on considère un modèle polynomiale, paramétré par les coefficients $(\\alpha_0, \\alpha_1)$ : $f(\\hat{\\epsilon}_t^i) = \\alpha_0 + \\alpha_1 \\hat{\\epsilon}_t^{i2}$.\n\nOn cherche à minimiser l'erreur en norme L1: $\\sum_{i=1}^N |\\xi_t^i|$, ce qui revient à faire un regression médiane.\n\nLa raison de pourquoi on choisit d'estimer par la médiane est du à sa robustesse face aux outliers.\n\nEnfin, on choisit $\\epsilon^\\star$ de façon à ce que $f(\\epsilon^\\star) = |\\log 0.9|$. En effet, puisque $\\epsilon^\\star$ est la borne supérieure, on considère donc le pire cas, puisque plus $\\epsilon$ est grand, plus les résultats sont mauvais. Ainsi en remplaçant cette valeurs dans $|\\Delta E_t^i|$, on obtient un taux d'acceptation de 90% malgré le fait qu'on se place dans la borne supérieure.","block_group":"8e793a97538248bcbe66ad0675765621"},{"cell_type":"markdown","metadata":{"cell_id":"b3cf350737ac43d088a82780b01a8a68","deepnote_cell_type":"markdown"},"source":"$\\textbf{Description de l'algorithme de Pre-tuning du noyau HMC}$\n\nL'algorithme de Pre-tuning se déroule comme suit :\n\n**Initialisation :**  On se situe à l'étape $t-1$ de l'algorithme SMC, et on dispose de particules $\\{\\tilde{x_{t-1}^i}\\}_{i=1,...,N}$. On a également un flot de HMC $\\varphi$, et un $\\epsilon^\\star_t$. \n\n\n**Pour chaque particule $i \\in \\{1,...,N\\}$ :**\n\nOn tire $\\hat{\\epsilon}_t^i \\sim \\mathcal{U}([0, \\epsilon^\\star_t])$ et $\\hat{L}_t^i \\sim \\mathcal{U}([0, L_{max}])$\nOn tire $q_t^i \\sim \\mathcal{N}(0, M_{t-1})$\nOn applique HMC pour obtenir $(\\hat{q}_t^i, \\hat{p}_t^i)$\nOn calcule $\\Delta E_t^i$ et le critère de performance $\\tilde{\\Lambda}(\\tilde{x}_{t-1}^i, \\hat{x}_{t}^i)$\n\n**A la fin :**\n    On calcule $\\epsilon_t^\\star$ par quantile regression comme expliqué precedemment\n    On calcule des poids $w_t^i$ proportionnels à $\\tilde{\\Lambda}(\\tilde{x}_{t-1}^i, \\hat{x}_{t}^i)$\n    On resample les $\\{\\hat{\\epsilon}_t^i, \\hat{L}_t^i\\}$ avec les poids $w_t^i$, notés  $\\{{\\epsilon}_t^i, {L}_t^i\\}$\n\n**Sortie :** $\\{{\\epsilon}_t^i, {L}_t^i\\}$ et $\\epsilon_t^\\star$","block_group":"ce214ec797f14758880528d60b18d5fe"},{"cell_type":"markdown","metadata":{"cell_id":"d40a58daa7fa4b458cde4ef6aba4317e","deepnote_cell_type":"markdown"},"source":"## $\\textbf{Experimentation}$ : ","block_group":"f566f8a35ee54d63ba4952eef2a7777b"},{"cell_type":"code","metadata":{"source_hash":"adbc13f5","execution_start":1713204167034,"execution_millis":3567,"deepnote_to_be_reexecuted":false,"cell_id":"6a4b19e1c47346d387c752169374fbbf","deepnote_cell_type":"code"},"source":"N, n = 500, 5\nXR, Y = sample_Y(n)\nprint(f\"Vrai X : {XR}, Y : {Y}\")\nprint(f\"Esperance a posteriori réelle : {scipy.stats.beta(1 + Y.sum().cpu(), 1 + n - Y.sum().cpu()).mean()}\")\n\nclass TunedHmcParameters:\n    def __init__(self, eps_star, L, M, N):\n        self.eps_star = eps_star\n        self.epsilons = torch.rand((N, 1), device=device) * eps_star\n        self.M = M\n        self.L = L\n        self.N = N\n\n    def update_parameters(self, p0, q0, p, q, DeltaE):\n        norm = torch.einsum('ij,jk,ik->i', q0, h.M, q0).unsqueeze(1)\n        expDeltaE = torch.exp(DeltaE)\n        lambd = norm * torch.where(expDeltaE <= 1, expDeltaE, torch.ones(DeltaE.shape, device=device))\n        omega = lambd.squeeze().cpu().numpy()/lambd.cpu().numpy().sum()\n        self.epsilons = torch.from_numpy(\n            rng.choice(self.epsilons.cpu(), size=N, p=omega)\n        ).to(device)\n\n    def next_t(self):\n        self.epsilons = torch.rand((self.N, 1), device=device) * self.eps_star\n\nX, omegas = SMC(\n    Y, sample_X, N, p, l, \n    K_HMC, TunedHmcParameters(0.1, 10, torch.tensor([[1.]], device=device), N),\n    should_continue_markov, lambda t : lambda_get(10, t)\n)\nprint(f\"Estimateur de l'esperance a posteriori selon SMC : {X.mean()}\")","block_group":"4f7d9eba2f8d4d21b67fc49f0567a354","execution_count":5,"outputs":[{"name":"stdout","text":"Vrai X : tensor([0.4004]), Y : tensor([1., 0., 1., 0., 0.])\nEsperance a posteriori réelle : 0.4285714328289032\nEstimateur de l'esperance a posteriori selon SMC : 0.4100073277950287\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/43c91a64-af90-4dbd-b0ee-564f2c00d401","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"3a2c9e1efa644f98827f222d5ac17f4d","deepnote_cell_type":"markdown"},"source":"## $\\textit{Différences avec l'article}$ : \n\nPar souci de simplicité et d'implémentation, on a modifié certains points de l'algorithme et de la calibration présentés par les auteurs.\nLes différences avec l'algorithme proposé par l'article sont les suivantes : \n\n- Quand on arrive dans la boucle pour le HMC, l'algorithme génère N $\\epsilon_i \\sim \\mathcal{U}([0, \\epsilon^\\star])$ pour chaque particule. \n\n- A chaque itération du HMC dans l'algorithme implémenté, on calcule le critère de Rao-Blackwellized, les poids $w_i$ de chque $\\epsilon_i$, et on resample les $\\epsilon_i$ selon les performances. Les $\\epsilon$ avec des petits poids disparaissent, ainsi on a progressivement une convergence vers une liste des $\\epsilon_i$ où les poids sont les meilleurs, jusqu'à avoir 1 seul $\\epsilon$.\n- Le L est fixé et commun à toutes les particules dans l'algorithme implémenté.\n- On n'implémente pas de regression médiane et $\\epsilon^\\star$ est fixé dès le début et n'évolue pas selon les itérations.\n- Nous ne calibrons pas la matrice M","block_group":"21c7c82833b14c4884f5ec566c828dd5"},{"cell_type":"markdown","metadata":{"cell_id":"4ae399782b064ac6ab4af8f5dd0a08cf","deepnote_cell_type":"markdown"},"source":"### $\\textbf{IV - Conclusion}$","block_group":"6f28417b3b2440438037a11611ecb9c3"},{"cell_type":"markdown","metadata":{"cell_id":"3b4d298c7f9f4c718bede9e168c1fb8d","deepnote_cell_type":"markdown"},"source":"On a donc revu les méthodes SMC et HMC. On a introduit l'algorithme HMC dans SMC. Cet article propose des méthodes  de calibration de HMC dans SMC, que nous avons présentées et implémentées avec quelques simplifications. Notre calibration ne présente pas d'améliorations notables par rapport à la version dans calibration. Cela peut s'expliquer par les simplifications effectuées.","block_group":"8f20747ea0de421bad68688ccb76d52e"},{"cell_type":"markdown","metadata":{"cell_id":"2b1a949e4d634c7da0276ef4312ee7a2","deepnote_cell_type":"markdown"},"source":"### $\\textbf{Références}$ :","block_group":"658c827b4fdb495c80720b47b907a98e"},{"cell_type":"markdown","metadata":{"cell_id":"73b8b22985eb4730a1d22875b2e234b4","deepnote_cell_type":"markdown"},"source":"### $\\textit{Alexander Buchholz, Nicolas Chopin, Pierre E. Jacob}$\n   $\\textit{MRC Biostatistics Unit, University of Cambridge}$\n   $\\textit{ENSAE-CREST}$\n   $\\textit{Department of Statistics, Harvard University}$\n\n### $\\textit{Jasra et al., 2011}$ \n### $\\textit{Schäfer and Chopin, 2013}$\n### $\\textit{effective sample size - Kong et al., 1994}$\n### $\\textit{Agapiou et al., 2017}$\n\n### $\\textit{Fearnhead, P. and Taylor, B. M. (2013). *An adaptive sequential Monte Carlo sampler*.}$ \n   $\\textit{Bayesian Analysis, 8(2):411–438}$\n","block_group":"45605e7dde6d4003bdaa09ecaeab16dd"},{"cell_type":"markdown","metadata":{"cell_id":"c028a1d6ad854a62b2e8312651d0f504","deepnote_cell_type":"markdown"},"source":"","block_group":"5e5e57847cbd4e0387931eb9304ab9e1"},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=0ce0e88e-d80d-4010-9886-0b33e6492711' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"a4e1c9d32ce14a6086e804cc789b7ac2","deepnote_execution_queue":[]}}