{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4901f03a-7b0a-4955-9ad8-e022c24501d3",
   "metadata": {},
   "source": [
    "Massive parallel programming on GPUs and applications, by Lokman ABBAS TURKI  \n",
    "\n",
    "# 4. Add arrays with Numba jit and tensors multiplication with PyTorch\n",
    "\n",
    "## 4.1 Objective\n",
    "\n",
    "The main purpose of this lab is to show that there are other options for GPU parallelization that are conceptually very close to the use of CUDA API with C/C++ language. At the same time, this is an additional opportunity to become familiar with CUDA syntax by implementing simple examples.\n",
    "\n",
    "With Python, multiple options to use GPUs are possible. The tensor library PyTorch is certainly the most used one. We can also use CuPy or Numba jit (Just-in-time compilation) for usual array computations. In this lab, we use both the Numba jit and PyTorch with documentation found at \n",
    "\n",
    "[Numba for CUDA GPUs](https://numba.pydata.org/numba-doc/dev/cuda/)\n",
    "\n",
    "[PYTORCH DOCUMENTATION](https://pytorch.org/docs/stable/index.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da33bfd9-76ea-4fdd-9961-bcbfa9361a01",
   "metadata": {},
   "source": [
    "## 4.2 Content\n",
    "\n",
    "First, we need to import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6008012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "import numpy as np\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bee307-0a41-43fd-8e75-049955642508",
   "metadata": {},
   "source": [
    "\n",
    "### 4.2.1 Array addition with Numba jit \n",
    "\n",
    "a) Define arrays a and b with a size of 100000000 values using function arange.\n",
    "\n",
    "b) Calling function time.time(), compute the execution time of the addition on the host.\n",
    "\n",
    "c) Using the documentation, write a kernel that adds an array a to an array b and puts the result in c.\n",
    "\n",
    "d) Using function zeros, resets the values in array c.\n",
    "\n",
    "e) Using to_device function transfer the values of a to aGPU, of b to bGPU, and of c to cGPU.\n",
    "\n",
    "f) Execute the addition kernel with the appropriate number of threads and number of blocks, and compute its execution time.\n",
    "\n",
    "\n",
    "### 4.2.2 Tensor multiplication with PyTorch\n",
    "\n",
    "In the following questions, tensors are created and randomly filled using torch.rand.\n",
    "\n",
    "a) Define tensors A and B on the host then perform the multiplication and compute the execution time.\n",
    "\n",
    "b) Define tensors A and B on the device then perform the multiplication and compute the execution time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6612efee-b4f5-48b9-bd30-f0ec17ba373b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
