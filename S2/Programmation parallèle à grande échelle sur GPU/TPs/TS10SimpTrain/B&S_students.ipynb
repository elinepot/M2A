{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c4c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e1797f-efba-4b01-9f11-82e0728ba3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self, n_input, n_hidden1, n_hidden2, n_hidden3, n_output):\n",
    "        \"\"\"\n",
    "        :param n_input: number of perceptrons for the input layer (int)\n",
    "        :param n_hidden: number of perceptrons for the hidden layer (int)\n",
    "        :param n_output: number of perceptrons for the output layer (int)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(n_input, n_hidden1)\n",
    "        self.hidden2 = nn.Linear(n_hidden1, n_hidden2)\n",
    "        self.hidden3 = nn.Linear(n_hidden2, n_hidden3)\n",
    "        self.output = nn.Linear(n_hidden3, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Neural network input (2d torch tensor with arbitrary number of rows and n_input columns)\n",
    "        :return: 2d torch tensor: Neural network output (same number of rows as x, n_output columns)\n",
    "        \"\"\"\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = F.relu(self.hidden3(x))\n",
    "        x = self.output(x)\n",
    "        return x  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ced2aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self, n_input, n_hidden1, n_hidden2, n_output):\n",
    "        \"\"\"\n",
    "        :param n_input: number of perceptrons for the input layer (int)\n",
    "        :param n_hidden: number of perceptrons for the hidden layer (int)\n",
    "        :param n_output: number of perceptrons for the output layer (int)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(n_input, n_hidden1)\n",
    "        self.hidden2 = nn.Linear(n_hidden1, n_hidden2)\n",
    "        self.output = nn.Linear(n_hidden2, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Neural network input (2d torch tensor with arbitrary number of rows and n_input columns)\n",
    "        :return: 2d torch tensor: Neural network output (same number of rows as x, n_output columns)\n",
    "        \"\"\"\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        return x  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e9c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NC = norm.cdf #cumulative function of N(0,1), CPU version\n",
    "\n",
    "def BS_price(S0, K, sig, r, T):\n",
    "    \"\"\"\n",
    "    :param S0: time t stock price (stricly positive number)\n",
    "    :param K: Call strike (stricly positive number)\n",
    "    :param sig: volatility (stricly positive number)\n",
    "    :param r: interest rate (stricly positive number)\n",
    "    :param T: maturity time (stricly positive number)\n",
    "    :return : BS price of call option at time 0 with maturity T by closed form formula\n",
    "    \"\"\"\n",
    "    d1=(np.log(S0/K)+(r+sig**2/2)*T)/(sig*np.sqrt(T))\n",
    "    d2=d1-sig*np.sqrt(T)\n",
    "    return S0*NC(d1)-K*np.exp(-r*T)*NC(d2)\n",
    "\n",
    "NC_GPU = torch.special.ndtr #cumulative function of N(0,1), GPU version\n",
    "\n",
    "def BS_price_GPU(S0, K, sig, r, T):\n",
    "    \"\"\"\n",
    "    :param S0: time t stock price (stricly positive number)\n",
    "    :param K: Call strike (stricly positive number)\n",
    "    :param sig: volatility (stricly positive number)\n",
    "    :param r: interest rate (stricly positive number)\n",
    "    :param T: maturity time (stricly positive number)\n",
    "    :return : BS price of call option at time 0 with maturity T by closed form formula\n",
    "    \"\"\"\n",
    "    d1=(torch.log(S0/K)+(r+sig**2/2)*T)/(sig*torch.sqrt(T))\n",
    "    d2=d1-sig*torch.sqrt(T)\n",
    "    return S0*NC_GPU(d1)-K*torch.exp(-r*T)*NC_GPU(d2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6c24a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                    \"\"\" CPU version\"\"\"\n",
    "\n",
    "K = 100\n",
    "T = 1\n",
    "sig = 0.2\n",
    "r = 0.1\n",
    "batch_size = 2048\n",
    "S0_min, S0_max = 50, 150\n",
    "\n",
    "NET = net(1, 100, 100, 1)\n",
    "#NET = net(1, 200, 200, 200, 1)\n",
    "optimizer = Adam(NET.parameters(), lr=0.0005) \n",
    "loss_func = nn.MSELoss(reduction = 'mean')  \n",
    "\n",
    "\"\"\"Uniform generation\"\"\"\n",
    "t_ = time()\n",
    "S0 = torch.tensor(np.random.uniform(S0_min, S0_max, batch_size*1024*2), dtype=torch.float)\n",
    "print(\"(CPU) S0 generation time :\", time()-t_)\n",
    "\n",
    "S0 = S0.view(-1,1)\n",
    "dataloader = torch.utils.data.DataLoader(S0, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "t_ = time()\n",
    "for data in dataloader :\n",
    "    optimizer.zero_grad()\n",
    "    TRUE_price = BS_price(data, K, sig, r, T).float()\n",
    "    NET_price = NET(data)\n",
    "    loss = loss_func(TRUE_price, NET_price)\n",
    "    #loss = torch.mean((TRUE_price - NET_price)**2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(\"(CPU) training time :\", time() - t_)\n",
    "\n",
    "\"\"\"Price generation\"\"\"\n",
    "t_ = time()\n",
    "price = BS_price(S0, K, sig, r, T).float()\n",
    "print(\"(CPU) price time :\", time()-t_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87ed9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = torch.arange(50., 150., 0.2).view(-1,1).float()\n",
    "S_numpy = S.numpy()\n",
    "plt.figure()\n",
    "plt.plot(S_numpy, BS_price(S_numpy, K, sig, r, T), color='r', alpha=0.5, label = \"True price\")\n",
    "plt.plot(S_numpy, NET(S).detach().numpy(), color='b', alpha = 0.5, label = \"NET price\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"S0\")\n",
    "plt.ylabel(\"price\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb227c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                       \"\"\" GPU version \"\"\"\n",
    "K = torch.tensor(100, device = device)\n",
    "#K = 100\n",
    "T = torch.tensor(1, device = device)\n",
    "#T = 1\n",
    "sig = torch.tensor(0.2, device = device)\n",
    "#sig = 0.2\n",
    "r = torch.tensor(0.1, device = device)\n",
    "#r = 0.1\n",
    "\n",
    "#NET = net(1, 200, 200, 200, 1).cuda(device)\n",
    "NET = net(1, 100, 100, 1).cuda(device)\n",
    "optimizer = Adam(NET.parameters(), lr = 0.0005) \n",
    "loss_func = nn.MSELoss(reduction = 'mean')\n",
    "\n",
    "#data\n",
    "t_ = time()\n",
    "S0 = torch.tensor(np.random.uniform(S0_min, S0_max, batch_size*1024*2), dtype=torch.float, device = device)\n",
    "torch.cuda.synchronize()\n",
    "print(\"(GPU) S0 generation time :\", time()-t_)\n",
    "\n",
    "\n",
    "S0 = S0.view(-1,1)\n",
    "dataloader = torch.utils.data.DataLoader(S0, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "t_ = time()\n",
    "for data in dataloader :\n",
    "    optimizer.zero_grad()\n",
    "    TRUE_price = price = BS_price_GPU(data, K, sig, r, T).float()\n",
    "    NET_price = NET(data)\n",
    "    \n",
    "    loss = loss_func(TRUE_price, NET_price)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "torch.cuda.synchronize()\n",
    "print(\"(GPU) training time :\", time() - t_)\n",
    "\n",
    "t_ = time()\n",
    "price = BS_price_GPU(S0, K, sig, r, T).float()\n",
    "print(\"(GPU) price time :\", time()-t_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed5f5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "S = torch.arange(50., 150., 0.2, device = device).view(-1,1).float()\n",
    "plt.figure()\n",
    "plt.plot(S_numpy, BS_price_GPU(S, K, sig, r, T).cpu().numpy(), color='r', alpha=0.5, label = \"True price\")\n",
    "plt.plot(S_numpy, NET(S).detach().cpu().numpy(), color='b', alpha = 0.5, label = \"NET price\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"S0\")\n",
    "plt.ylabel(\"price\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f8bd37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebabccb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
